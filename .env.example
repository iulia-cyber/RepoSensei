# Repo-Sensei server
# Copy this file to .env and set your values. Do not commit .env.
# Leave HOST empty for best localhost compatibility on Windows.
HOST=
PORT=4173

# PostgreSQL connection
DB_ENABLED=1
PGHOST=127.0.0.1
PGPORT=5432
PGUSER=postgres
PGPASSWORD=your_postgres_password
PGDATABASE=postgres

# Optional full URL (overrides PG* when provided)
# DATABASE_URL=postgres://postgres:YOUR_PASSWORD@127.0.0.1:5432/postgres

# Hugging Face model (optional)
# Set both values to enable model generation in /api/chat.
HF_MODEL=Qwen/Qwen2.5-7B-Instruct
HF_API_KEY=
HF_TIMEOUT_MS=25000

# OpenAI fallback (optional)
# Used for chat generation fallback and embeddings when configured.
OPENAI_API_KEY=
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_EMBED_MODEL=text-embedding-3-small
OPENAI_EMBED_DIMENSIONS=1536
OPENAI_TIMEOUT_MS=30000

# Vector embeddings
EMBEDDINGS_ENABLED=1
EMBEDDING_CHUNK_LINES=120
EMBEDDING_CHUNK_OVERLAP=24
EMBEDDING_MAX_CHUNKS_PER_SYNC=1200

# Optional GitHub URL inspect mode (no clone)
# For higher rate limits on private repos, set a token with repo read access.
GITHUB_TOKEN=
GITHUB_SNAPSHOT_MAX_FILES=220
GITHUB_SNAPSHOT_MAX_BYTES=18000000
GITHUB_SNAPSHOT_CONCURRENCY=8
